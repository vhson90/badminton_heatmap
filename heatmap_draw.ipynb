{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ecb1adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:00<00:00, 10.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã nhấn 'q' trong quá trình xử lý video. Thoát.\n",
      "Xử lý hoàn tất. Tổng frames: 53, Tổng thời gian: 7.34s, FPS trung bình: 7.22\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "\n",
    "# --- Khởi tạo MediaPipe Pose ---\n",
    "mp_pose = mp.solutions.pose\n",
    "pose_detector = mp_pose.Pose(static_image_mode=False,\n",
    "                             model_complexity=0,\n",
    "                             smooth_landmarks=True,\n",
    "                             enable_segmentation=False,\n",
    "                             min_detection_confidence=0.35,\n",
    "                             min_tracking_confidence=0.35)\n",
    "\n",
    "# --- Các hàm phụ trợ ---\n",
    "def sort_corners(pts_array):\n",
    "    if not isinstance(pts_array, np.ndarray): pts_array = np.array(pts_array)\n",
    "    if pts_array.ndim == 3: pts_array = pts_array.reshape(-1, 2)\n",
    "    if pts_array.shape[0] != 4: return None\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts_array.sum(axis=1)\n",
    "    rect[0], rect[2] = pts_array[np.argmin(s)], pts_array[np.argmax(s)]\n",
    "    idx_tl, idx_br = np.argmin(s), np.argmax(s)\n",
    "    remaining_indices = [i for i in range(4) if i not in [idx_tl, idx_br]]\n",
    "    if len(remaining_indices) == 2:\n",
    "        pt1, pt2 = pts_array[remaining_indices[0]], pts_array[remaining_indices[1]]\n",
    "        if pt1[1] < pt2[1]: rect[1], rect[3] = pt1, pt2\n",
    "        elif pt2[1] < pt1[1]: rect[1], rect[3] = pt2, pt1\n",
    "        else: rect[1], rect[3] = (pt1, pt2) if pt1[0] > pt2[0] else (pt2, pt1)\n",
    "    else: return None\n",
    "    return rect.astype(np.int32)\n",
    "\n",
    "def is_point_in_box(px, py, x1, y1, x2, y2, tol=0):\n",
    "    return (x1 - tol <= px <= x2 + tol and y1 - tol <= py <= y2 + tol)\n",
    "\n",
    "def is_box_intersecting_polygon(box, polygon_pts):\n",
    "    x1, y1, x2, y2 = box\n",
    "    box_poly_pts = np.array([[x1,y1],[x2,y1],[x2,y2],[x1,y2]], dtype=np.float32)\n",
    "    if polygon_pts.ndim == 2: poly_cv = polygon_pts.reshape(-1,1,2).astype(np.float32)\n",
    "    elif polygon_pts.ndim == 3 and polygon_pts.shape[1]==1 and polygon_pts.shape[2]==2: poly_cv = polygon_pts.astype(np.float32)\n",
    "    else: return False\n",
    "    for pt in box_poly_pts:\n",
    "        if cv2.pointPolygonTest(poly_cv, (float(pt[0]), float(pt[1])), False) >= 0: return True\n",
    "    for pt in poly_cv.reshape(-1,2):\n",
    "        if x1 <= pt[0] <= x2 and y1 <= pt[1] <= y2: return True\n",
    "    return False\n",
    "\n",
    "def draw_badminton_court_lines(image, W, H, color=(255, 255, 255), thickness=1):\n",
    "    if W <= 0 or H <= 0: return\n",
    "    cv2.rectangle(image, (0, 0), (W - 1, H - 1), color, thickness)\n",
    "    cv2.line(image, (0, H // 2), (W - 1, H // 2), color, thickness) # Net line\n",
    "\n",
    "    # Standard badminton court ratios (length 13.4m, width 6.1m for doubles)\n",
    "    court_length_ratio_ref = 13.4\n",
    "    court_width_ratio_ref = 6.1\n",
    "\n",
    "    single_line_offset_x = int((0.46 / court_width_ratio_ref) * W)\n",
    "    cv2.line(image, (single_line_offset_x, 0), (single_line_offset_x, H - 1), color, thickness)\n",
    "    cv2.line(image, (W - 1 - single_line_offset_x, 0), (W - 1 - single_line_offset_x, H - 1), color, thickness)\n",
    "\n",
    "    short_service_line_offset_y = int((1.98 / court_length_ratio_ref) * H)\n",
    "    y_ssl_top = H // 2 - short_service_line_offset_y\n",
    "    y_ssl_bottom = H // 2 + short_service_line_offset_y\n",
    "    cv2.line(image, (single_line_offset_x, y_ssl_top), (W - 1 - single_line_offset_x, y_ssl_top), color, thickness)\n",
    "    cv2.line(image, (single_line_offset_x, y_ssl_bottom), (W - 1 - single_line_offset_x, y_ssl_bottom), color, thickness)\n",
    "\n",
    "    cv2.line(image, (W // 2, y_ssl_top), (W // 2, 0), color, thickness) # Center line top half\n",
    "    cv2.line(image, (W // 2, y_ssl_bottom), (W // 2, H - 1), color, thickness) # Center line bottom half\n",
    "\n",
    "    long_service_line_doubles_offset_y = int((0.76 / court_length_ratio_ref) * H)\n",
    "    y_lsld_top = long_service_line_doubles_offset_y\n",
    "    y_lsld_bottom = H - 1 - long_service_line_doubles_offset_y\n",
    "    cv2.line(image, (0, y_lsld_top), (W - 1, y_lsld_top), color, thickness)\n",
    "    cv2.line(image, (0, y_lsld_bottom), (W - 1, y_lsld_bottom), color, thickness)\n",
    "\n",
    "def process_video_for_court_boundary(video_path):\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Lỗi: Không thể mở video từ '{video_path}'\"); return\n",
    "\n",
    "    # --- Heatmap Grid Configuration ---\n",
    "    GRID_COLS = 30\n",
    "    GRID_ROWS = 40\n",
    "\n",
    "    # Preserve original dest_rect dimensions as per user's last code\n",
    "    dest_rect_width = 610\n",
    "    dest_rect_height = int(dest_rect_width * (67.1 / 61.0))\n",
    "    dest_rect_corners_dst = np.array([\n",
    "        [[0,0]],[[dest_rect_width-1,0]],\n",
    "        [[dest_rect_width-1,dest_rect_height-1]],[[0,dest_rect_height-1]]], dtype=np.float32)\n",
    "\n",
    "    clahe_heatmap = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    clahe_video = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    last_known_roi_corners = None\n",
    "\n",
    "    default_warped_display = np.zeros((dest_rect_height, dest_rect_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Preserve original default_schematic dimensions as per user's last code\n",
    "    default_schematic_display_width = 300\n",
    "    default_schematic_display_height = int(300 * (13.4/6.1)) # This uses badminton aspect ratio\n",
    "    default_schematic_court_img = np.zeros((default_schematic_display_height, default_schematic_display_width, 3), dtype=np.uint8)\n",
    "    # Draw faint court lines on default schematic as a placeholder\n",
    "    draw_badminton_court_lines(default_schematic_court_img, default_schematic_display_width, default_schematic_display_height, (70,70,70), 1)\n",
    "    cv2.putText(default_schematic_court_img, \"No schematic data\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (220,220,220), 1)\n",
    "\n",
    "    all_schematic_positions_history = []\n",
    "    frame_count = 0\n",
    "    start_time_overall = time.time()\n",
    "    user_exited_during_video = False # Flag for user pressing 'q' during video\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Hết video.\")\n",
    "            break # Exit main loop\n",
    "\n",
    "        display_frame = np.copy(frame)\n",
    "        warped_display = default_warped_display.copy()\n",
    "        # schematic_court_img will be determined based on H_matrix presence\n",
    "\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        v_enh = clahe_video.apply(v)\n",
    "        hsv_enh = cv2.merge([h, s, v_enh])\n",
    "        mask = cv2.inRange(hsv_enh, np.array([30,30,30]), np.array([90,255,255]))\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((5,5),np.uint8), iterations=2)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((11,11),np.uint8), iterations=3)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        current_roi_corners = None\n",
    "        if contours:\n",
    "            cnt = max(contours, key=cv2.contourArea)\n",
    "            # Area threshold to filter small contours\n",
    "            if cv2.contourArea(cnt) > 0.005 * frame.shape[0] * frame.shape[1]:\n",
    "                poly = cv2.approxPolyDP(cnt, 0.025 * cv2.arcLength(cnt, True), True)\n",
    "                if len(poly) == 4: current_roi_corners = sort_corners(poly)\n",
    "\n",
    "        final_roi_corners = current_roi_corners if current_roi_corners is not None else last_known_roi_corners\n",
    "        if final_roi_corners is not None: last_known_roi_corners = final_roi_corners\n",
    "\n",
    "        players_on_court, player_midpoints_original_with_color = [], []\n",
    "        player_transformed_points_with_color = []\n",
    "\n",
    "        H_matrix = None\n",
    "        # Default schematic dimensions if H_matrix is not found or invalid\n",
    "        schematic_w_actual = default_schematic_display_width\n",
    "        schematic_h_actual = default_schematic_display_height\n",
    "        limit_x1_w, limit_y1_w = 0, 0\n",
    "        limit_x2_w, limit_y2_w = schematic_w_actual, schematic_h_actual # Default to full default schematic size\n",
    "\n",
    "        if final_roi_corners is not None and final_roi_corners.shape == (4,2):\n",
    "            yolo_res = model(frame, classes=[0], verbose=False)\n",
    "            persons = []\n",
    "            for res in yolo_res:\n",
    "                for box_obj in res.boxes:\n",
    "                    b = box_obj.xyxy[0].cpu().numpy().astype(int)\n",
    "                    if is_box_intersecting_polygon(b, final_roi_corners):\n",
    "                        persons.append({'box':b, 'area':(b[2]-b[0])*(b[3]-b[1])})\n",
    "            players_on_court = sorted(persons, key=lambda x: x['area'], reverse=True)[:2]\n",
    "            colors = [(255,0,0), (0,0,255)] # Player 1 Blue, Player 2 Red\n",
    "\n",
    "            for i, p_data in enumerate(players_on_court):\n",
    "                x1_p,y1_p,x2_p,y2_p = p_data['box'] # Renamed to avoid conflict\n",
    "                cv2.rectangle(display_frame, (x1_p,y1_p), (x2_p,y2_p), colors[i], 2)\n",
    "                roi_img = frame[y1_p:y2_p, x1_p:x2_p]\n",
    "                if roi_img.size == 0: continue\n",
    "                pose_res = pose_detector.process(cv2.cvtColor(roi_img, cv2.COLOR_BGR2RGB))\n",
    "                if pose_res.pose_landmarks:\n",
    "                    lm = pose_res.pose_landmarks.landmark\n",
    "                    h_r, w_r, _ = roi_img.shape\n",
    "                    try:\n",
    "                        lh, rh = lm[mp_pose.PoseLandmark.LEFT_HEEL.value], lm[mp_pose.PoseLandmark.RIGHT_HEEL.value]\n",
    "                        if lh.visibility > 0.5 and rh.visibility > 0.5:\n",
    "                            lx_f, ly_f = int(lh.x*w_r)+x1_p, int(lh.y*h_r)+y1_p\n",
    "                            rx_f, ry_f = int(rh.x*w_r)+x1_p, int(rh.y*h_r)+y1_p\n",
    "                            tol = int(0.05*min(x2_p-x1_p,y2_p-y1_p))\n",
    "                            if is_point_in_box(lx_f,ly_f,x1_p,y1_p,x2_p,y2_p,tol) and \\\n",
    "                               is_point_in_box(rx_f,ry_f,x1_p,y1_p,x2_p,y2_p,tol):\n",
    "                                mid_x, mid_y = int((lx_f+rx_f)/2), int((ly_f+ry_f)/2)\n",
    "                                player_midpoints_original_with_color.append(((mid_x,mid_y), colors[i]))\n",
    "                                cv2.circle(display_frame, (mid_x,mid_y), 7, colors[i], -1)\n",
    "                                cv2.circle(display_frame, (mid_x,mid_y), 8, (255,255,255),1)\n",
    "                    except (IndexError, Exception): pass\n",
    "            \n",
    "            try:\n",
    "                H_matrix_cand, _ = cv2.findHomography(final_roi_corners.astype(np.float32), dest_rect_corners_dst)\n",
    "                if H_matrix_cand is not None and H_matrix_cand.shape == (3,3):\n",
    "                    H_matrix = H_matrix_cand\n",
    "                    warped_display = cv2.warpPerspective(frame, H_matrix, (dest_rect_width, dest_rect_height))\n",
    "                    \n",
    "                    h_w_display, w_w_display = dest_rect_height, dest_rect_width\n",
    "                    off_x_r, off_y_r = 0.081, 0.06 # Original offsets\n",
    "                    limit_x1_w_calc = int(w_w_display*off_x_r)\n",
    "                    limit_y1_w_calc = int(h_w_display*off_y_r)\n",
    "                    limit_x2_w_calc = w_w_display-int(w_w_display*off_x_r)\n",
    "                    limit_y2_w_calc = h_w_display-int(h_w_display*off_y_r)\n",
    "\n",
    "                    # Update actual limits and schematic dimensions only if H_matrix is valid\n",
    "                    limit_x1_w, limit_y1_w = limit_x1_w_calc, limit_y1_w_calc\n",
    "                    limit_x2_w, limit_y2_w = limit_x2_w_calc, limit_y2_w_calc\n",
    "                    schematic_w_actual = limit_x2_w - limit_x1_w\n",
    "                    schematic_h_actual = limit_y2_w - limit_y1_w\n",
    "                    \n",
    "                    lim_cnr_w = np.array([[[limit_x1_w,limit_y1_w]],[[limit_x2_w,limit_y1_w]],\n",
    "                                          [[limit_x2_w,limit_y2_w]],[[limit_x1_w,limit_y2_w]]], dtype=np.float32)\n",
    "                    \n",
    "                    if not np.array_equal(H_matrix, np.zeros((3,3))) and not np.array_equal(H_matrix, np.eye(3)):\n",
    "                        try:\n",
    "                            H_inv = np.linalg.inv(H_matrix)\n",
    "                            lim_cnr_orig = cv2.perspectiveTransform(lim_cnr_w, H_inv)\n",
    "                            if lim_cnr_orig is not None:\n",
    "                                cv2.polylines(display_frame, [np.round(lim_cnr_orig).astype(np.int32)], True, (0,255,255),3)\n",
    "                        except np.linalg.LinAlgError: H_matrix = None \n",
    "                    else: H_matrix = None \n",
    "\n",
    "                    cv2.rectangle(warped_display, (limit_x1_w,limit_y1_w), (limit_x2_w,limit_y2_w), (0,255,0),2)\n",
    "\n",
    "                    if player_midpoints_original_with_color and H_matrix is not None:\n",
    "                        pts_orig = np.array([[list(d[0]) for d in player_midpoints_original_with_color]], dtype=np.float32)\n",
    "                        pts_trans = cv2.perspectiveTransform(pts_orig, H_matrix)\n",
    "                        if pts_trans is not None:\n",
    "                            for i_pt, (orig_data, trans_pt) in enumerate(zip(player_midpoints_original_with_color, pts_trans[0])):\n",
    "                                color_loop = orig_data[1]\n",
    "                                tx, ty = int(trans_pt[0]), int(trans_pt[1])\n",
    "                                \n",
    "                                if 0 <= tx < w_w_display and 0 <= ty < h_w_display:\n",
    "                                    cv2.circle(warped_display, (tx,ty),7,color_loop,-1)\n",
    "                                    cv2.circle(warped_display,(tx,ty),8,(255,255,255),1)\n",
    "                                \n",
    "                                if limit_x1_w <= tx < limit_x2_w and limit_y1_w <= ty < limit_y2_w:\n",
    "                                    player_transformed_points_with_color.append(((tx,ty), color_loop))\n",
    "                                    schematic_px = tx - limit_x1_w\n",
    "                                    schematic_py = ty - limit_y1_w\n",
    "                                    if schematic_w_actual > 0 and schematic_h_actual > 0 and \\\n",
    "                                       0 <= schematic_px < schematic_w_actual and \\\n",
    "                                       0 <= schematic_py < schematic_h_actual:\n",
    "                                        all_schematic_positions_history.append((schematic_px, schematic_py))\n",
    "            except Exception: H_matrix = None\n",
    "\n",
    "        # Determine base for schematic court image\n",
    "        if H_matrix is not None and schematic_w_actual > 0 and schematic_h_actual > 0:\n",
    "            current_heatmap_base = np.zeros((schematic_h_actual, schematic_w_actual, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            current_heatmap_base = default_schematic_court_img.copy()\n",
    "\n",
    "\n",
    "        # Heatmap generation grid-based\n",
    "        if H_matrix is not None and schematic_w_actual > 0 and schematic_h_actual > 0:\n",
    "            if all_schematic_positions_history:\n",
    "                heatmap_grid_counts = np.zeros((GRID_ROWS, GRID_COLS), dtype=np.float32)\n",
    "                \n",
    "                cell_width_on_schematic = schematic_w_actual / GRID_COLS\n",
    "                cell_height_on_schematic = schematic_h_actual / GRID_ROWS\n",
    "\n",
    "                if cell_width_on_schematic > 0 and cell_height_on_schematic > 0:\n",
    "                    for hx, hy in all_schematic_positions_history:\n",
    "                        grid_col = int(hx / cell_width_on_schematic)\n",
    "                        grid_row = int(hy / cell_height_on_schematic)\n",
    "                        \n",
    "                        grid_col = min(max(grid_col, 0), GRID_COLS - 1)\n",
    "                        grid_row = min(max(grid_row, 0), GRID_ROWS - 1)\n",
    "                        heatmap_grid_counts[grid_row, grid_col] += 1\n",
    "                \n",
    "                max_grid_count = np.max(heatmap_grid_counts)\n",
    "                if max_grid_count > 0:\n",
    "                    normalized_grid_counts = heatmap_grid_counts / max_grid_count\n",
    "                    \n",
    "                    upscaled_intensity_map_float = cv2.resize(normalized_grid_counts, \n",
    "                                                              (schematic_w_actual, schematic_h_actual), \n",
    "                                                              interpolation=cv2.INTER_LINEAR)\n",
    "                    \n",
    "                    upscaled_intensity_map_uint8 = (upscaled_intensity_map_float * 255).astype(np.uint8)\n",
    "                    heatmap_enhanced_uint8 = clahe_heatmap.apply(upscaled_intensity_map_uint8)\n",
    "                    heatmap_blurred_uint8 = cv2.GaussianBlur(heatmap_enhanced_uint8, (15, 15), 0) # Original blur kernel\n",
    "                    \n",
    "                    current_heatmap_base = cv2.applyColorMap(heatmap_blurred_uint8, cv2.COLORMAP_JET)\n",
    "            \n",
    "            # Draw court lines on top of the heatmap or black base\n",
    "            draw_badminton_court_lines(current_heatmap_base, schematic_w_actual, schematic_h_actual, color=(255,255,255), thickness=1)\n",
    "            \n",
    "            # Draw current player positions on top\n",
    "            for transformed_pt_data in player_transformed_points_with_color:\n",
    "                (tx, ty), player_color = transformed_pt_data \n",
    "                pt_x_on_schematic = tx - limit_x1_w\n",
    "                pt_y_on_schematic = ty - limit_y1_w\n",
    "                if 0 <= pt_x_on_schematic < schematic_w_actual and 0 <= pt_y_on_schematic < schematic_h_actual:\n",
    "                    cv2.circle(current_heatmap_base, (pt_x_on_schematic, pt_y_on_schematic), 7, player_color, -1)\n",
    "                    cv2.circle(current_heatmap_base, (pt_x_on_schematic, pt_y_on_schematic), 8, (0,0,0), 1)\n",
    "        \n",
    "        schematic_court_img = current_heatmap_base\n",
    "        \n",
    "        if H_matrix is None and final_roi_corners is not None:\n",
    "            cv2.polylines(display_frame, [final_roi_corners.reshape(-1,1,2)], True, (0,0,255),1)\n",
    "\n",
    "        cv2.imshow('Phat hien san va VDV', display_frame)\n",
    "        cv2.imshow('San Dau Da Lam Phang (Top-down)', warped_display)\n",
    "        cv2.imshow('San Cau Long Mo Phong (Heatmap)', schematic_court_img)\n",
    "        \n",
    "        frame_count += 1\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            user_exited_during_video = True\n",
    "            print(\"Đã nhấn 'q' trong quá trình xử lý video. Thoát.\")\n",
    "            break\n",
    "\n",
    "    # After the main loop (video ended or 'q' was pressed)\n",
    "    if not user_exited_during_video and frame_count > 0:\n",
    "        print(\"Video đã kết thúc. Nhấn 'q' trên một trong các cửa sổ để đóng.\")\n",
    "        while True:\n",
    "            key_after_video = cv2.waitKey(30) & 0xFF\n",
    "            if key_after_video == ord('q'):\n",
    "                break\n",
    "            # Check if windows were closed manually, if so, break\n",
    "            # This can be problematic and OS-dependent, so a simpler 'q' to quit is often more robust.\n",
    "            try:\n",
    "                if cv2.getWindowProperty('Phat hien san va VDV', cv2.WND_PROP_VISIBLE) < 1 or \\\n",
    "                   cv2.getWindowProperty('San Dau Da Lam Phang (Top-down)', cv2.WND_PROP_VISIBLE) < 1 or \\\n",
    "                   cv2.getWindowProperty('San Cau Long Mo Phong (Heatmap)', cv2.WND_PROP_VISIBLE) < 1:\n",
    "                    print(\"Một cửa sổ đã bị đóng thủ công.\")\n",
    "                    break\n",
    "            except cv2.error: # Catch error if a window was already destroyed\n",
    "                print(\"Lỗi truy cập thuộc tính cửa sổ, có thể cửa sổ đã bị đóng.\")\n",
    "                break\n",
    "            time.sleep(0.01) # Reduce CPU usage in this waiting loop\n",
    "\n",
    "    cap.release()\n",
    "    pose_detector.close()\n",
    "    cv2.destroyAllWindows()\n",
    "    total_time = time.time() - start_time_overall\n",
    "    if total_time > 0 and frame_count > 0:\n",
    "        print(f\"Xử lý hoàn tất. Tổng frames: {frame_count}, Tổng thời gian: {total_time:.2f}s, FPS trung bình: {frame_count/total_time:.2f}\")\n",
    "    else: print(\"Xử lý hoàn tất.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    video_file_path = 'demo.mp4' \n",
    "    try:\n",
    "        with open(video_file_path,'rb') as f:pass\n",
    "        process_video_for_court_boundary(video_file_path)\n",
    "    except FileNotFoundError: print(f\"Lỗi: Không tìm thấy file '{video_file_path}'.\")\n",
    "    except Exception as e: print(f\"Lỗi không mong muốn: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
